{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a9dcd33",
   "metadata": {},
   "source": [
    "# Get weather from Meteostat API\n",
    "\n",
    "![Image](https://s3.amazonaws.com/rapidapi-prod-user/32834e52-7dfc-4286-b233-cd1b9aa0b6d3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1420f2cf",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "1. `requests` - to request data through APIs\n",
    "2. `pandas`\n",
    "3. `time` - for sleep time function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfb3d05",
   "metadata": {},
   "source": [
    "## Adding API key in .env file\n",
    "We need to define a variable that includes our API key that will be used for the appid parameter. Why? Because we need to authenticate ourselves to the API when we send a request, so the API knows that we have a registered account and can notify us in case we reach our query limit.\n",
    "\n",
    "To do this,\n",
    "\n",
    "1. Go to you user profile and go to \"My API keys\"\n",
    "2. Copy your API key.\n",
    "3. Add a variable called \"meteostat_api_key\" to your .env file and put your API key in there. Don't forget to save it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c306bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to pull the API key from the .env, we need to import and run the load_dotenv function from the dotenv module first.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbada22",
   "metadata": {},
   "source": [
    "## API Call\n",
    "\n",
    "Next, as mentioned above the URL of the API has to be specified. In this example we are going to pull current weather data. The documentation for this API can be found here: https://rapidapi.com/meteostat/api/meteostat/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172def17",
   "metadata": {},
   "source": [
    "### URL Description\n",
    "The url shown below is what needs to be used in order to connect to the API.\n",
    "\n",
    "We can see that the url has \n",
    "* a fixed part: 'https://meteostat.p.rapidapi.com/point/hourly?'\n",
    "* and a variable part: 'lat:, lon:, start:, end:, rapidapi-key:, rapidapi_host:'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9424f",
   "metadata": {},
   "source": [
    "### Paramters Description\n",
    "While the fixed part stays constant, the variable part consists of query strings or parameters, some optional some mandatory, which can be used to select or filter data.\n",
    "\n",
    "Below are the optional and required parameters when pulling current weather data by latitude and longitude.\n",
    "\n",
    "* latitude\n",
    "* longitude\n",
    "* start\n",
    "* end\n",
    "* rapidapi_key\n",
    "* rapidapi_host"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ad7f7f",
   "metadata": {},
   "source": [
    "### Final API Call in loop for all airports\n",
    "As the final step before we can do our first API call, we have to put all necessary parameters we chose (our API key, paramters) into a dictionary. We call it \"parameters\", but you can choose any name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the url\n",
    "url = 'https://meteostat.p.rapidapi.com/point/hourly?'\n",
    "\n",
    "# Set locations\n",
    "lat_and_lon = [['33.6367', '-84.428101'],\n",
    "                ['33.56290054', '-86.75350189'],\n",
    "                ['32.3111991882', '-90.0758972168'],\n",
    "                ['34.729400634799994', '-92.2242965698'],\n",
    "                ['29.99340057373047', '-90.25800323486328'],\n",
    "                ['36.281898', '-94.306801']]\n",
    "\n",
    "airport_codes = ['ATL', 'BHM', 'JAN', 'LIT', 'MSY', 'XNA']               \n",
    "\n",
    "# Create empty dataframe, will be used to append each location's weather data\n",
    "meteostat_details_df = pd.DataFrame([])\n",
    "\n",
    "# Loop through all locations\n",
    "for index, lonlat in enumerate(lat_and_lon):\n",
    "    \n",
    "    parameters = {\n",
    "    'lat': lat_and_lon[index][0],\n",
    "    'lon': lat_and_lon[index][1],\n",
    "    'start': '2019-07-11',\n",
    "    'end': '2019-07-15',\n",
    "    'rapidapi-key': os.getenv('meteostat_api_key'),\n",
    "    'rapidapi-host': 'meteostat.p.rapidapi.com'}\n",
    "\n",
    "    print(parameters)\n",
    "    # Create final url\n",
    "    #url_f = url + lonlat + parameters\n",
    "    \n",
    "    # Request data from url\n",
    "    r = requests.get(url, parameters)\n",
    "    \n",
    "    time.sleep(1) #uncomment if you run into a query limit\n",
    "    \n",
    "    # Decode repsonse with json decoder\n",
    "    meteostat_details_temp = r.json()\n",
    "\n",
    "    # Flatten json response\n",
    "    meteostat_details_temp_df = pd.json_normalize(meteostat_details_temp, sep=\"_\", record_path='data')\n",
    "\n",
    "    print(airport_codes[index])\n",
    "    \n",
    "    meteostat_details_temp_df['airport_code'] = airport_codes[index]\n",
    "    \n",
    "    # concatenate dataframes\n",
    "    meteostat_details_df = pd.concat([meteostat_details_df, meteostat_details_temp_df], ignore_index=True)\n",
    "\n",
    "# Print final dataset weather_df\n",
    "meteostat_details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4cdf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteostat_details_df[meteostat_details_df['airport_code']=='XNA']['coco'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddfb5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteostat_weather_df = meteostat_details_df[meteostat_details_df['airport_code']!='XNA'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899f1279",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteostat_weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66f1c5e",
   "metadata": {},
   "source": [
    "## Inserting meteostat data into the database\n",
    "The last step is to write this table into our database. We already created functions to help us do this using the sql_functions.py file. \n",
    "If the credentials and functions are set up correctly from the previous notebook, we can go ahead and import the helper function from the sql_functions.py file to get our connection engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d66aefd",
   "metadata": {},
   "source": [
    "### Get Engine, Set table name and schema\n",
    "Next, set the table name variable. This will be name of the table that will be written to the PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09557561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sql_functions import get_engine\n",
    "schema = 'cgn_analytics_22_3' # UPDATE 'TABLE_SCHEMA' based on schema used in class \n",
    "engine = get_engine() # assign engine to be able to query against the database\n",
    "table_name = 'meteostat_jsmn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08e619e",
   "metadata": {},
   "source": [
    "### Write the dataset to the database\n",
    "The final step is to write the dataset to the database.  \n",
    "Complete the code below and write the dataset stored in planes_in_both to the PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "if engine!=None:\n",
    "    try:\n",
    "        meteostat_weather_df.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nf_sql')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) \n[Clang 13.0.1 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a81d278bed5b5b59425dcb5a82ce505657686243c184b4a6b67e69d01c4d432e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
